{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36e701e7",
   "metadata": {},
   "source": [
    "# OpenAI Quickstart Guide\n",
    "\n",
    "From the official documentation available at: https://platform.openai.com/docs/overview\n",
    "\n",
    "You can use different models depending on your needs, check them at: https://platform.openai.com/docs/models\n",
    "\n",
    "Note: check the pricing before using a model! --> https://platform.openai.com/docs/pricing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c31972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "from pprint import pprint\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if the API key is set\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY environment variable is not set.\")\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = api_key\n",
    "\n",
    "# Initialize OpenAI client\n",
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42d97fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response = \n",
      "{'background': False,\n",
      " 'conversation': None,\n",
      " 'created_at': 1756824476.0,\n",
      " 'error': None,\n",
      " 'id': 'resp_68b7039cbc8081a09904d346cce7fef20c4314fb28353153',\n",
      " 'incomplete_details': None,\n",
      " 'instructions': None,\n",
      " 'max_output_tokens': None,\n",
      " 'max_tool_calls': None,\n",
      " 'metadata': {},\n",
      " 'model': 'gpt-4.1-2025-04-14',\n",
      " 'object': 'response',\n",
      " 'output': [ResponseOutputMessage(id='msg_68b703a79ad081a09f691e5ed603d3fa0c4314fb28353153', content=[ResponseOutputText(annotations=[], text='Under a silver moon, a gentle unicorn tiptoed through a field of glowing stars, spreading sweet dreams to everyone fast asleep.', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')],\n",
      " 'parallel_tool_calls': True,\n",
      " 'previous_response_id': None,\n",
      " 'prompt': None,\n",
      " 'prompt_cache_key': None,\n",
      " 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None),\n",
      " 'safety_identifier': None,\n",
      " 'service_tier': 'default',\n",
      " 'status': 'completed',\n",
      " 'store': True,\n",
      " 'temperature': 1.0,\n",
      " 'text': ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'),\n",
      " 'tool_choice': 'auto',\n",
      " 'tools': [],\n",
      " 'top_logprobs': 0,\n",
      " 'top_p': 1.0,\n",
      " 'truncation': 'disabled',\n",
      " 'usage': ResponseUsage(input_tokens=18, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=27, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=45),\n",
      " 'user': None}\n",
      "\n",
      "response.output_text = \n",
      "Under a silver moon, a gentle unicorn tiptoed through a field of glowing stars, spreading sweet dreams to everyone fast asleep.\n"
     ]
    }
   ],
   "source": [
    "# Make a request to the model\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a one-sentence bedtime story about a unicorn.\"\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "print(\"Response = \")\n",
    "pprint(dict(response))\n",
    "print(f\"\\nresponse.output_text = \\n{response.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6caaee",
   "metadata": {},
   "source": [
    "You can specify instructions to provide high-level instructions adopted as an overall context for your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d7fecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response with instructions = \n",
      "{'background': False,\n",
      " 'conversation': None,\n",
      " 'created_at': 1756760035.0,\n",
      " 'error': None,\n",
      " 'id': 'resp_68b607e34f208197ab5c49642b94e1840d7e0e684004ad84',\n",
      " 'incomplete_details': None,\n",
      " 'instructions': 'Answer in rhyme and with a cheerful style.',\n",
      " 'max_output_tokens': None,\n",
      " 'max_tool_calls': None,\n",
      " 'metadata': {},\n",
      " 'model': 'gpt-4.1-2025-04-14',\n",
      " 'object': 'response',\n",
      " 'output': [ResponseOutputMessage(id='msg_68b607e3e97c8197abf77607bb79c85d0d7e0e684004ad84', content=[ResponseOutputText(annotations=[], text='A butterfly flutters in sunlight so bright,  \\nWings painted with splashes of pure delight.  \\nIt dances on breezes, a soft, gentle flight,  \\nA whisper of wonder, a beautiful sight.\\n\\nFrom blossom to blossom it skips on the way,  \\nPainting the garden with colors of May.  \\nIt sips from the nectar, then giggles with glee,  \\nA speckled-winged artist as light as can be.\\n\\nWith silken wings open, it glimmers and spins,  \\nA jewel on a breeze where the magic begins!  \\nOh, butterfly darling, so lovely and free—  \\nKeep showing the world how joyful you’ll be!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')],\n",
      " 'parallel_tool_calls': True,\n",
      " 'previous_response_id': None,\n",
      " 'prompt': None,\n",
      " 'prompt_cache_key': None,\n",
      " 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None),\n",
      " 'safety_identifier': None,\n",
      " 'service_tier': 'default',\n",
      " 'status': 'completed',\n",
      " 'store': True,\n",
      " 'temperature': 1.0,\n",
      " 'text': ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'),\n",
      " 'tool_choice': 'auto',\n",
      " 'tools': [],\n",
      " 'top_logprobs': 0,\n",
      " 'top_p': 1.0,\n",
      " 'truncation': 'disabled',\n",
      " 'usage': ResponseUsage(input_tokens=27, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=137, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=164),\n",
      " 'user': None}\n",
      "\n",
      "response_with_instructions.output_text = \n",
      "A butterfly flutters in sunlight so bright,  \n",
      "Wings painted with splashes of pure delight.  \n",
      "It dances on breezes, a soft, gentle flight,  \n",
      "A whisper of wonder, a beautiful sight.\n",
      "\n",
      "From blossom to blossom it skips on the way,  \n",
      "Painting the garden with colors of May.  \n",
      "It sips from the nectar, then giggles with glee,  \n",
      "A speckled-winged artist as light as can be.\n",
      "\n",
      "With silken wings open, it glimmers and spins,  \n",
      "A jewel on a breeze where the magic begins!  \n",
      "Oh, butterfly darling, so lovely and free—  \n",
      "Keep showing the world how joyful you’ll be!\n"
     ]
    }
   ],
   "source": [
    "# Example of using the 'instructions' and 'reasoning' parameters in the model request\n",
    "response_with_instructions = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=\"Write a poem about a butterfly.\",\n",
    "    instructions=\"Answer in rhyme and with a cheerful style.\")\n",
    "\n",
    "# With some models you can also specify the reasoning effort parameter, e.g.    \n",
    "# reasoning={\"effort\": \"low\"})\n",
    "  \n",
    "print(\"Response with instructions = \")\n",
    "pprint(dict(response_with_instructions))\n",
    "print(f\"\\nresponse_with_instructions.output_text = \\n{response_with_instructions.output_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd33373",
   "metadata": {},
   "source": [
    "## Structured Output\n",
    "\n",
    "Structured Output allows you to receive responses from the model in a predefined format, such as JSON or other structured data types. This is useful when you need the model's output to be machine-readable for further processing, integration, or automation. By specifying the desired structure, you can ensure consistency and make it easier to extract specific information from the model's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410008c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math_reasoning = \n",
      "\n",
      "{'final_answer': 'x = -15/4 (which equals -3.75)',\n",
      " 'steps': [Step(explanation='Start with the equation and isolate the term containing x by subtracting 7 from both sides.', output='8x + 7 = -23  ⇒  8x = -23 - 7 = -30'),\n",
      "           Step(explanation='Now solve for x by dividing both sides by 8.', output='x = -30/8'),\n",
      "           Step(explanation='Simplify the fraction by dividing numerator and denominator by 2.', output='x = -15/4 = -3.75'),\n",
      "           Step(explanation='Check the solution by substituting x back into the original equation: compute 8x + 7 with x = -15/4.', output='8(−15/4) + 7 = −30 + 7 = −23, which matches the original right-hand side.')]}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class Step(BaseModel):\n",
    "    explanation: str\n",
    "    output: str\n",
    "\n",
    "class MathReasoning(BaseModel):\n",
    "    steps: list[Step]\n",
    "    final_answer: str\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-5-mini\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful math tutor. Guide the user through the solution step by step.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": \"how can I solve 8x + 7 = -23\"},\n",
    "    ],\n",
    "    text_format=MathReasoning,\n",
    ")\n",
    "\n",
    "math_reasoning = dict(response.output_parsed)\n",
    "print(\"math_reasoning = \\n\")\n",
    "pprint(math_reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d42b284",
   "metadata": {},
   "source": [
    "Or again you can use structured output to request the response to be in a specific format, e.g:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71083585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response = \n",
      "\n",
      "CalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "class CalendarEvent(BaseModel):\n",
    "    name: str\n",
    "    date: str\n",
    "    participants: list[str]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[\n",
    "        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Alice and Bob are going to a science fair on Friday.\",\n",
    "        },\n",
    "    ],\n",
    "    text_format=CalendarEvent,\n",
    ")\n",
    "\n",
    "print(\"response = \\n\")\n",
    "pprint(response.output_parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642ad01a",
   "metadata": {},
   "source": [
    "When using Structured Outputs consider also to check for refusals and specify what to do in case of a refusal (i.e. when the model refuses to answer).\n",
    "\n",
    "Check the official documentation here --> https://platform.openai.com/docs/guides/structured-outputs#refusals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd1e7e",
   "metadata": {},
   "source": [
    "### Difference between `system`, `user`, and other roles in prompt content\n",
    "\n",
    "**System role:** The `system` message sets the behavior, context, or instructions for the model. It defines how the model should respond and can guide its tone, style, or constraints. For example, you can instruct the model to act as a math tutor or to answer in a specific format.\n",
    "\n",
    "**User role:** The `user` message represents the actual input or question from the end user. This is the prompt or query you want the model to answer.\n",
    "\n",
    "**Other roles (e.g., `assistant`):** Some APIs support additional roles like `assistant`, which can be used to provide previous model responses in a conversation, or custom roles for advanced workflows. These help maintain context in multi-turn conversations.\n",
    "\n",
    "In summary, `system` sets instructions/context, `user` provides the query, and other roles help structure multi-turn or complex interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e3de64",
   "metadata": {},
   "source": [
    "# Image generation\n",
    "\n",
    "To generate images with OpenAI APIs, use the `image_generation` tool in your request. Specify your prompt in the `input` field and set the model (e.g., `\"gpt-5\"`). The API will return a base64-encoded image, which you can decode and save as a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b55000fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI() \n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=\"Generate an image of gray tabby cat hugging an otter with an orange scarf\",\n",
    "    tools=[{\"type\": \"image_generation\"}],\n",
    ")\n",
    "\n",
    "# Save the image to a file\n",
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "    \n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"otter.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6797843",
   "metadata": {},
   "source": [
    "## Multi-turn image generation\n",
    "\n",
    "With the Responses API, you can build multi-turn conversations involving image generation either by providing image generation calls outputs within context (you can also just use the image ID), or by using the \n",
    "previous_response_id\n",
    "parameter. This makes it easy to iterate on images across multiple turns—refining prompts, applying new instructions, and evolving the visual output as the conversation progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f73e6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"Generate an image of gray tabby cat hugging an otter with an orange scarf\",\n",
    "    tools=[{\"type\": \"image_generation\"}],\n",
    ")\n",
    "\n",
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "\n",
    "    with open(\"cat_and_otter.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))\n",
    "\n",
    "\n",
    "# Follow up\n",
    "\n",
    "response_fwup = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    previous_response_id=response.id,\n",
    "    input=\"Now make it look realistic\",\n",
    "    tools=[{\"type\": \"image_generation\"}],\n",
    ")\n",
    "\n",
    "image_data_fwup = [\n",
    "    output.result\n",
    "    for output in response_fwup.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "if image_data_fwup:\n",
    "    image_base64 = image_data_fwup[0]\n",
    "    with open(\"cat_and_otter_realistic.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84af14c",
   "metadata": {},
   "source": [
    "You can also use streaming image generation to stream partial images as they are generated, if you are interested check here --> https://platform.openai.com/docs/guides/image-generation#streaming\n",
    "\n",
    "Moreover, note that when using some models (such as gpt-4.1) the model refines your prompt to enhance the result, if you are interested check here --> https://platform.openai.com/docs/guides/image-generation#revised-prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1986e3fa",
   "metadata": {},
   "source": [
    "## Create a new image using image references\n",
    "\n",
    "You can create an image by using one or more other images as reference.\n",
    "\n",
    "With the Responses API, you can provide input images in 2 different ways:\n",
    "\n",
    "- By providing an image as a Base64-encoded data URL\n",
    "- By providing a file ID (created with the Files API)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524b9fc7",
   "metadata": {},
   "source": [
    "### Creating a Base64-encoded data URL from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedd0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def create_file(file_path):\n",
    "  with open(file_path, \"rb\") as file_content:\n",
    "    result = client.files.create(\n",
    "        file=file_content,\n",
    "        purpose=\"vision\",\n",
    "    )\n",
    "    return result.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106bfbd5",
   "metadata": {},
   "source": [
    "### Create a file ID from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37dca181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        base64_image = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return base64_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01b92e7",
   "metadata": {},
   "source": [
    "Now, let us generate an image from these "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de2ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"Generate a photorealistic image of a gift basket on a white background \n",
    "labeled 'Relax & Unwind' with a ribbon and handwriting-like font, \n",
    "containing all the items in the reference pictures.\"\"\"\n",
    "\n",
    "base64_image1 = encode_image(\"soap.png\")\n",
    "base64_image2 = encode_image(\"bath-bomb.png\")\n",
    "file_id1 = create_file(\"body-lotion.png\")\n",
    "file_id2 = create_file(\"incense-kit.png\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": prompt},\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image1}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"image_url\": f\"data:image/jpeg;base64,{base64_image2}\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"file_id\": file_id1,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"file_id\": file_id2,\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    tools=[{\"type\": \"image_generation\"}],\n",
    ")\n",
    "\n",
    "image_generation_calls = [\n",
    "    output\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "image_data = [output.result for output in image_generation_calls]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"gift-basket.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))\n",
    "else:\n",
    "    print(response.output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaec83",
   "metadata": {},
   "source": [
    "## Edit an image using a mask\n",
    "\n",
    "When editing an image you can also provide a mask to indicate where the image should be edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e0d8960",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "fileId = create_file(\"sunlit_lounge.png\")\n",
    "maskId = create_file(\"mask.png\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"input_text\",\n",
    "                    \"text\": \"generate an image of the same sunlit indoor lounge area with a pool but the pool should contain a flamingo\",\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"file_id\": fileId,\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"image_generation\",\n",
    "            \"quality\": \"high\",\n",
    "            \"input_image_mask\": {\n",
    "                \"file_id\": maskId,\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"lounge.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94689cf",
   "metadata": {},
   "source": [
    "## Increasing Input fidelity in image generation\n",
    "\n",
    "When dealing with images that require accurate preservation of elements (such as faces or logos) you can increase input fidelity by setting the <code>input_fidelity</code> parameter to <code>high</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f427198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import base64\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "womanId = create_file(\"woman_futuristic.jpg\")\n",
    "logoId = create_file(\"brain_logo.png\")\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"input_text\", \"text\": \"Add the logo to the woman's top, as if stamped into the fabric.\"},\n",
    "                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"file_id\": womanId,\n",
    "                },\n",
    "                                {\n",
    "                    \"type\": \"input_image\",\n",
    "                    \"file_id\": logoId,\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    "    tools=[{\"type\": \"image_generation\", \"input_fidelity\": \"high\"}],\n",
    ")\n",
    "\n",
    "# Extract the edited image\n",
    "image_data = [\n",
    "    output.result\n",
    "    for output in response.output\n",
    "    if output.type == \"image_generation_call\"\n",
    "]\n",
    "\n",
    "if image_data:\n",
    "    image_base64 = image_data[0]\n",
    "    with open(\"woman_with_logo.png\", \"wb\") as f:\n",
    "        f.write(base64.b64decode(image_base64))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7ec23",
   "metadata": {},
   "source": [
    "## Additional custom options and features\n",
    "\n",
    "You can check for additional features and options such as the size, quality and the transparency here --> https://platform.openai.com/docs/guides/image-generation#size-and-quality-options  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed093ddc",
   "metadata": {},
   "source": [
    "# Analyze images\n",
    "\n",
    "You can use the vision capabilities of the model to analyze the content of an image, such as text or many other visual elements like shapes, colors, objects and textures.\n",
    "\n",
    "Input images must meet the following requirements to be used in the API.\n",
    "\n",
    "| Requirement         | Details                                                                                   |\n",
    "|---------------------|-------------------------------------------------------------------------------------------|\n",
    "| Supported file types| PNG (.png), JPEG (.jpeg, .jpg), WEBP (.webp), Non-animated GIF (.gif)                     |\n",
    "| Size limits         | Up to 50 MB total payload size per request<br>Up to 500 individual image inputs per request|\n",
    "| Other requirements  | No watermarks or logos<br>No NSFW content<br>Clear enough for a human to understand        |\n",
    "\n",
    "For more info check here --> https://platform.openai.com/docs/guides/images-vision#analyze-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbde65a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image shows a wooden boardwalk pathway extending through a lush, green grassy field. The pathway leads into the distance, surrounded by tall grass and some scattered bushes and trees. The sky above is vast and blue with some scattered white clouds. The scene appears calm and natural, likely in a park or nature reserve.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    input=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"input_text\", \"text\": \"what's in this image?\"},\n",
    "            {\n",
    "                \"type\": \"input_image\",\n",
    "                \"image_url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "            },\n",
    "        ],\n",
    "    }],\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai_cookbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
